{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWwKG4l1HFWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbf9303b-a55a-4582-9a3a-4b2845a7286e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "1ikVB4zgHzVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#страшный график корелляции t от x3\n",
        "import seaborn as sns\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv', nrows = 10000)\n",
        "sns.countplot(x = 't', hue = 'x3', data = data)"
      ],
      "metadata": {
        "id": "6864kbsYIpaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заполнение t средним значением"
      ],
      "metadata": {
        "id": "CjLO2JXKk5ps"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "#попытка заполнить пропущенные значения t с помощью случайного леса\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "for data in pd.read_csv('/content/drive/MyDrive/Colab Notebooks/train.csv', chunksize=10 ** 6):\n",
        "\n",
        "  # Разделение данных на train_data и missing_data\n",
        "  train_data = data[~data['t'].isnull() ] # В этой дейте все ок\n",
        "  missing_data = data[data['t'].isnull()] # А вот эта дейта с пропущенными признаками\n",
        "\n",
        "  # Разделение train_data на признаки и целевую переменную\n",
        "  X_train = train_data.drop(['t'], axis=1)\n",
        "  y_train_x1 = train_data['t']\n",
        "\n",
        "\n",
        "  # Создание и обучение модели для x1\n",
        "  model_x1 = RandomForestRegressor()\n",
        "  model_x1.fit(X_train, y_train_x1)\n",
        "\n",
        "\n",
        "  # Получение предсказанных значений для missing_data\n",
        "  X_missing = missing_data.drop(['t'], axis=1)\n",
        "  missing_data['t'] = model_x1.predict(X_missing)\n",
        "\n",
        "\n",
        "\n",
        "  # Объединение train_data и missing_data с заполненными значениями\n",
        "  filled_data = pd.concat([train_data, missing_data])\n",
        "\n",
        "  # Попытка заполнить средним значением\n",
        "  mean_t = data['t'].mean()\n",
        "  filled_data = data.fillna({'t': mean_t})\n",
        "\n",
        "  filled_data.update(missing_data)\n",
        "\n",
        "  # Вывод заполненного набора данных\n",
        "  print(filled_data)\n",
        "  filled_data.to_csv('filled.csv', index=False)\n"
      ],
      "metadata": {
        "id": "g9-yAXGJk43r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor# реализуем с помощью линейной регрессии\n",
        "\n",
        "\n",
        "\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/dima/test_etalon40.csv') #данные, на которых учится (объединяем несколько test_etalon в один)\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv') #данные для теста\n",
        "train_data['x1'] = train_data['x1'].fillna(0)\n",
        "# Разделение на признаки x и целевую переменную (y), \n",
        "x_train = train_data[['t', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']]\n",
        "y_train = train_data['x1']\n",
        "x_test = test_data[['t', 'x2', 'x3']]\n",
        "\n",
        "# Добавление недостающих признаков в тестовых данных\n",
        "\n",
        "missing_columns = ['x4', 'x5', 'x6', 'x7', 'x8']\n",
        "for column in missing_columns:\n",
        "   x_test[column] = 0\n",
        "model = HistGradientBoostingRegressor()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "predicted_values = model.predict(x_test)\n",
        "\n",
        "# Заполнение пропущенных значений в test['x1'] предсказанными значениями\n",
        "test_data['x1'].fillna(pd.Series(predicted_values), inplace=True)\n",
        "\n",
        "# Добавление предсказанных значений в тестовый набор\n",
        "#test_data['predicted_x1'] = predicted_values\n",
        "\n",
        "# Сохранение тестового набора с предсказанными значениями в файл\n",
        "test_data\n",
        "test_data.to_csv('predicted.csv', index=False)\n"
      ],
      "metadata": {
        "id": "XrTHXTFQs8Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor# \n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "filename = '/content/drive/MyDrive/Colab Notebooks/finalized_model_for_fulldata.sav' # Загружаем предыдущий стейт машины\n",
        "\n",
        "loaded_model = pickle.load(open(filename, 'rb'))\n",
        "\n",
        "train_data = pd.read_csv('/content/drive/MyDrive/dima1/die6_merged.csv') # Все как обычно -- вводим тренировочные переменные, переменные для предикта\n",
        "\n",
        "x_train = train_data[['t', 'x2', 'x3', 'x4', 'x5', 'x6', 'x7', 'x8']]\n",
        "y_train = train_data['x1']\n",
        "\n",
        "test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/test.csv')\n",
        "\n",
        "missing_data = test_data [test_data ['x1'].isnull()] \n",
        "\n",
        "\n",
        "x_test = test_data[['t', 'x2', 'x3']]\n",
        "\n",
        "missing_columns = ['x4', 'x5', 'x6', 'x7', 'x8']  \n",
        "for column in missing_columns:\n",
        "    x_test[column] = 1\n",
        "\n",
        "loaded_model.fit(x_train, y_train) # Загруженная машина предсказывает значения\n",
        "\n",
        "predicted_values = loaded_model.predict(x_test)\n",
        "\n",
        "\n",
        "test_data['x1'].fillna(pd.Series(predicted_values), inplace=True)\n",
        "missing_data ['x1'].fillna(pd.Series(predicted_values), inplace=True)\n",
        "\n",
        "test_data.to_csv('/content/drive/MyDrive/Colab Notebooks/predicted_values2.csv', index=False) # Дейта со всеми значениями x1\n",
        "\n",
        "missing_data.to_csv('/content/drive/MyDrive/Colab Notebooks/missing_data.csv', index=False) #Дейта только с пропущенными значениями x1\n",
        "\n",
        "filename = '/content/drive/MyDrive/Colab Notebooks/finalized_model_for22.sav' # Сохраняем текущее состояние для машины\n",
        "pickle.dump(loaded_model, open(filename, 'wb'))\n"
      ],
      "metadata": {
        "id": "TU1wXH8xVCbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# А это рассчет x4..x8"
      ],
      "metadata": {
        "id": "oKKmibrfV8Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gnvJUISQfexq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import networkx as nx\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/data/die6.csv',nrows = 1e2)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwmI7Po9mH9s"
      },
      "outputs": [],
      "source": [
        "attr= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/attr.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFY4Oe8fGXQj"
      },
      "outputs": [],
      "source": [
        "ro = attr.value_counts('ego_id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1Y1Ka8ajiVe"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import math\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "def calc_x4_x7(data,start_index,end_index):\n",
        "  data_sort = data\n",
        "  data_sort['x4']=0\n",
        "  data_sort['x5']=0\n",
        "  data_sort['x6']=0\n",
        "  data_sort['x7']=0\n",
        "  data_sort['x8']=0\n",
        "  def count_age_koeff(age_diff):\n",
        "    if age_diff<10:\n",
        "      return 1\n",
        "    else:\n",
        "      return -math.exp(abs(age_diff-10))/math.exp(3)\n",
        "  for i in range (0,end_index):\n",
        "    temp = data_sort.loc[i]\n",
        "    try:\n",
        "      data_sort.loc[i,'x6']=ro[temp['ego_id']]\n",
        "    #except:\n",
        "    #  pass\n",
        "\n",
        "    #try:\n",
        "      temp_u = attr[attr['u']==temp['u']][attr['ego_id']==temp['ego_id']]\n",
        "      temp_v = attr[attr['u']==temp['v']][attr['ego_id']==temp['ego_id']]\n",
        "      u_age = temp_u.values[0][2]\n",
        "      v_age = temp_v.values[0][2]\n",
        "      u_sex = temp_u.values[0][4]\n",
        "      v_sex = temp_v.values[0][4]\n",
        "      u_sch = temp_u.values[0][5]\n",
        "      v_sch = temp_v.values[0][5]\n",
        "      u_uni = temp_u.values[0][6]\n",
        "      v_uni = temp_v.values[0][6]\n",
        "      u_cit = temp_u.values[0][3]\n",
        "      v_cit = temp_v.values[0][3]\n",
        "      u_cit = temp_u.values[0][3]\n",
        "      v_cit = temp_v.values[0][3]\n",
        "      #print(f\"u_sch={u_sch}, v_sch={v_sch}, u_uni = {u_uni},v_uni = {v_uni}\")\n",
        "      temp_x4=count_age_koeff(abs(u_age-v_age))*(0.6*0.0**abs(u_sex-v_sex) + 0.4*0.0**0.0**abs(u_sex-v_sex))\n",
        "      temp_x5=0.75*0.0**abs(u_sch-v_sch)*0.0**0.0**abs(u_sch+1)*0.0**0.0**abs(v_sch+1)+0.5*0.0**abs(u_uni-v_uni)*0.0**0.0**abs(u_uni+1)*0.0**0.0**abs(v_uni+1)\n",
        "      temp_x7 = 1 if u_cit-v_cit == 0 else 0.01\n",
        "      #print(temp_x5)\n",
        "      data_sort.loc[i,'x4']=temp_x4\n",
        "      data_sort.loc[i,'x5']=temp_x5\n",
        "      data_sort.loc[i,'x7']=temp_x7\n",
        "    except:\n",
        "      #if i%10==0:\n",
        "        #print(f\"error{i}\") \n",
        "        #print (temp)\n",
        "      pass\n",
        "    data_sort.to_csv(f'/content/drive/MyDrive/dima1_1/test_etalon{start_index}.csv')\n",
        "#calc_x4_x7(data,0,100)\n",
        "ROWS=1000\n",
        "START=0\n",
        "END=50\n",
        "for j in range(START,END):\n",
        "  temp_data = pd.read_csv('/content/drive/MyDrive/data/die6.csv',nrows = ROWS,skiprows=range(1, j*ROWS))\n",
        "  calc_x4_x7(temp_data,j,ROWS)\n"
      ]
    }
  ]
}